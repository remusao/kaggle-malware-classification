#!/usr/bin/env python
# -*- coding: utf-8 -*-


from __future__ import print_function
from sklearn.externals import joblib
import numpy as np
import multiprocessing
import minibelt
import libarchive.public


def hdf5_store_sparse(X, f, name="X"):
    # TODO
    # Efficiently store a sparse matrix in hdf5
    # by extracting data, indices and indptr (+size)
    # http://stackoverflow.com/questions/11129429/storing-numpy-sparse-matrix-in-hdf5-pytables
    pass


def hdf5_load_sparse(f, name="X"):
    pass


def file_iter(path):
    """ Iterate on training"""
    with libarchive.public.file_reader(path) as archive:
        for entry in archive:
            filename = entry.pathname
            content = '\n'.join(entry.get_blocks())
            yield (filename, content)


def multiclass_log_loss(y_true, y_pred, eps=1e-15):
    """Multi class version of Logarithmic Loss metric.
    https://www.kaggle.com/wiki/MultiClassLogLoss

    Parameters
    ----------
    y_true : array, shape = [n_samples]
            true class, intergers in [0, n_classes - 1)
    y_pred : array, shape = [n_samples, n_classes]

    Returns
    -------
    loss : float
    """
    predictions = np.clip(y_pred, eps, 1 - eps)

    # normalize row sums to 1
    predictions /= predictions.sum(axis=1)[:, np.newaxis]

    actual = np.zeros(y_pred.shape)
    n_samples = actual.shape[0]
    actual[np.arange(n_samples), y_true.astype(int)] = 1
    vectsum = np.sum(actual * np.log(predictions))
    loss = -1.0 / n_samples * vectsum
    return loss


def dump_classifier(clf, path):
    joblib.dump(clf, path)


def load_classifier(path):
    return joblib.load(path)


def parallel_map(func, images, *args, **kwargs):
    verbose = kwargs.get('verbose', True)
    n_sample = len(images)
    result = []
    index = 0
    pool = multiprocessing.Pool(multiprocessing.cpu_count())
    # Compute features for each sample
    for chunk in minibelt.chunks(images, 1000):
        if verbose:
            print(100 * index / n_sample, '%')
        features_set = pool.map(func, chunk)
        result.extend(features_set)
        index += len(features_set)
    return result
